import streamlit as st
from groq import Groq

SYSTEM_PROMPT = """
Voc√™ √© um Assistente Especialista em Machine Learning, Deep Learning, MLOps, LLMs e Explicabilidade de Modelos (XAI).

Seu papel √© ajudar usu√°rios a entender e aplicar:
- Algoritmos de Machine Learning
- Hiperpar√¢metros
- M√©tricas de avalia√ß√£o
- T√©cnicas de pr√©-processamento
- Feature engineering
- An√°lise de resultados
- Escolha de modelos
- Explicabilidade (SHAP, LIME, Feature Importance)
- Boas pr√°ticas de modelagem
- Arquitetura de projetos de dados e MLOps
- LLMs, embeddings, vetores e t√©cnicas de RAG
- Estrat√©gias avan√ßadas de prompting

REGRAS IMPORTANTES:
1. Explique conceitos de forma clara, objetiva e t√©cnica.
2. Sempre forne√ßa exemplos pr√°ticos ou trechos de c√≥digo relevantes.
3. Quando o usu√°rio pedir an√°lise de um modelo, pipeline ou dataset, solicite as informa√ß√µes necess√°rias.
4. Evite respostas gen√©ricas: responda com profundidade e racioc√≠nio estruturado.
5. Se a pergunta for incompleta, pe√ßa esclarecimentos antes de responder.
6. Mantenha tom profissional, did√°tico e acess√≠vel.
7. Ao explicar algoritmos, detalhe:
   - Objetivo
   - Como funciona
   - Vantagens
   - Limita√ß√µes
   - Hiperpar√¢metros essenciais
8. Ao explicar m√©tricas, sempre forne√ßa um exemplo num√©rico simples.
9. N√£o invente bibliotecas, fun√ß√µes ou sintaxes inexistentes.
10. Responda sempre em portugu√™s do Brasil.
11. Priorize exemplos reais encontrados em equipes de Machine Learning no mercado.

ORIENTA√á√ÉO ADICIONAL:
- Quando apropriado, ofere√ßa compara√ß√µes entre ML cl√°ssico e LLMs.
- Mostre quando embeddings, RAG ou LLMs podem substituir ou complementar t√©cnicas tradicionais.

OBJETIVO FINAL:
Ajudar o usu√°rio a compreender profundamenteMachine Learning, Deep Learning, MLOps e LLMs, interpretar modelos, tomar melhores decis√µes t√©cnicas e aprimorar solu√ß√µes de IA com precis√£o, clareza e boas pr√°ticas.
"""

def validar_api_key(api_key: str):
    if not api_key or api_key.strip() == "":
        return False, "API Key vazia. Insira uma para continuar."

    try:
        client = Groq(api_key=api_key)
        client.models.list()    
        return True, "API Key v√°lida!"
    except Exception:
        return False, "API Key inv√°lida ou n√£o foi poss√≠vel validar."


st.set_page_config(
    page_icon= "‚ö°",
    page_title= "AI Expert",
    layout= "wide",
    initial_sidebar_state="expanded"
)

if "show_sidebar" not in st.session_state:
    st.session_state.show_sidebar = True

if "api_valida" not in st.session_state:
    st.session_state.api_valida = False

if "messages" not in st.session_state:
  st.session_state.messages = []


with st.sidebar:

  if st.session_state.show_sidebar:
    st.title("‚öôÔ∏è Configura√ß√µes")
    st.subheader("üîë API")
    groq_api_key = st.text_input(
            "Groq API Key",
            type="password",
            placeholder="Digite sua API Key..."
    )
    
    if groq_api_key:
        valida, msg = validar_api_key(groq_api_key)
        if valida:
            st.success(msg)
            st.session_state.api_valida = True
        else:
            st.error(msg)
            st.session_state.api_valida = False
    else:
        st.warning("Digite sua API Key para continuar.")

    st.subheader("üßπ Sess√£o")
    if st.button("Limpar Conversa"):
        st.session_state["messages"] = []
        st.success("Conversa apagada!")

    st.markdown("---")
    st.caption("**AI Expert Chat** ‚Äî Assistente especializado em Machine Learning, XAI e LLMs.")
    st.caption("Desenvolvido por Daniel Coelho üöÄ")


st.title("IA Expert chat")

for message in st.session_state.messages:
  with st.chat_message(message["role"]):
    st.markdown(message["content"])

if not st.session_state.api_valida:
    st.warning("üîí Insira sua API Key na barra lateral para liberar o chat.")
    st.stop()

client = Groq(api_key=groq_api_key)

if prompt := st.chat_input():
  st.session_state.messages.append({"role": "user", "content": prompt})

  with st.chat_message("user"):
    st.markdown(prompt)
  
  message_api_key = [{"role": "system", "content": SYSTEM_PROMPT}]
  for msg in st.session_state.messages:
    message_api_key.append(msg)

  with st.chat_message("assistant"):
    with st.spinner("‚è≥Pensando..."):
            try:
              chat_completion = client.chat.completions.create(
                messages = message_api_key,
                model = "openai/gpt-oss-20b",
                temperature = 0.7,
                max_tokens = 204,
              )
              response =  chat_completion.choices[0].message.content
              st.markdown(response)
              st.session_state.messages.append({"role": "assistant", "content": response})
            except Exception as e:
              st.error(f"Erro na API: {e}")
